{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inspection and Cleaning Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Check data consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset_consistency(base_path):\n",
    "    \"\"\"\n",
    "    This function checks the consistency of the dataset structure:\n",
    "    1. Each subfolder must contain two subdirectories: 'original' and 'no_bg'.\n",
    "    2. Each subdirectory must contain exactly one image in JPEG format.\n",
    "    3. The two images must have the same dimensions.\n",
    "    \n",
    "    \"\"\"\n",
    "    inconsistencies = []  # List to collect any issues found\n",
    "\n",
    "    # Iterate through each subfolder in the dataset\n",
    "    for subfolder in os.listdir(base_path):\n",
    "        subfolder_path = os.path.join(base_path, subfolder)\n",
    "        \n",
    "        # Check if the item is a directory\n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            inconsistencies.append(f\"{subfolder_path} is not a folder.\")\n",
    "            continue\n",
    "        \n",
    "        # Check if the required subdirectories 'original' and 'no_bg' exist\n",
    "        original_path = os.path.join(subfolder_path, \"original\")\n",
    "        no_bg_path = os.path.join(subfolder_path, \"no_bg\")\n",
    "        \n",
    "        if not os.path.isdir(original_path) or not os.path.isdir(no_bg_path):\n",
    "            inconsistencies.append(f\"{subfolder_path} is missing 'original' or 'no_bg' folder.\")\n",
    "            continue\n",
    "        \n",
    "        # Retrieve all images in each folder\n",
    "        original_images = [f for f in os.listdir(original_path) if f.endswith(\".jpg\") or f.endswith(\".jpeg\")]\n",
    "        no_bg_images = [f for f in os.listdir(no_bg_path) if f.endswith(\".jpg\") or f.endswith(\".jpeg\")]\n",
    "        \n",
    "        # Ensure that each folder contains exactly one image\n",
    "        if len(original_images) != 1 or len(no_bg_images) != 1:\n",
    "            inconsistencies.append(f\"{subfolder_path} does not have exactly one image in each folder.\")\n",
    "            continue\n",
    "        \n",
    "        # Get the full paths of the images\n",
    "        original_image_path = os.path.join(original_path, original_images[0])\n",
    "        no_bg_image_path = os.path.join(no_bg_path, no_bg_images[0])\n",
    "        \n",
    "        # Compare the dimensions of the two images\n",
    "        try:\n",
    "            img1 = cv2.imread(original_image_path)  # Load the first image\n",
    "            img2 = cv2.imread(no_bg_image_path)    # Load the second image\n",
    "            \n",
    "            if img1 is None or img2 is None:\n",
    "                inconsistencies.append(f\"Images in {subfolder_path} could not be loaded.\")\n",
    "                continue\n",
    "            \n",
    "            if img1.shape[:2] != img2.shape[:2]:  # Compare height and width\n",
    "                inconsistencies.append(f\"Images in {subfolder_path} do not have the same dimensions.\")\n",
    "        except Exception as e:\n",
    "            # Catch and log any errors during image loading or processing\n",
    "            inconsistencies.append(f\"Error processing images in {subfolder_path}: {e}\")\n",
    "    \n",
    "    # Print the results\n",
    "    if not inconsistencies:\n",
    "        print(\"All dataset files are consistent!\")\n",
    "    else:\n",
    "        print(\"Inconsistencies found:\")\n",
    "        for issue in inconsistencies:\n",
    "            print(issue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Identify corrrupted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_problematic_images(folder_path):\n",
    "    \"\"\"\n",
    "    Checks for problematic images in a folder using TensorFlow.\n",
    "    \"\"\"\n",
    "    problematic_files = []\n",
    "\n",
    "    # Walk through the directory\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            try:\n",
    "                # Read and decode the image\n",
    "                img_raw = tf.io.read_file(file_path)\n",
    "                img = tf.image.decode_image(img_raw)\n",
    "                _ = img.numpy()  # Force evaluation of the tensor\n",
    "            except Exception as e:\n",
    "                print(f\"Problematic image found: {file_path} | Error: {e}\")\n",
    "                problematic_files.append(file_path)\n",
    "\n",
    "    return problematic_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Renaming and moving Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "# Función para reorganizar archivos\n",
    "def move_files(base_dir, images_dir, masks_dir):\n",
    "    \n",
    "    # Crear directorios de salida si no existen\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(masks_dir, exist_ok=True)\n",
    "\n",
    "    subfolders = [f.path for f in os.scandir(base_dir) if f.is_dir()]\n",
    "    image_count = 0  # Contador para renombrar las imágenes\n",
    "\n",
    "    for subfolder in subfolders:\n",
    "        original_dir = os.path.join(subfolder, \"original\")\n",
    "        no_bg_dir = os.path.join(subfolder, \"no_bg\")\n",
    "\n",
    "        if not os.path.exists(original_dir) or not os.path.exists(no_bg_dir):\n",
    "            print(f\"Skipping {subfolder}: Missing 'original' or 'no_bg' folder.\")\n",
    "            continue\n",
    "\n",
    "        # Procesar imágenes originales y máscaras\n",
    "        for img_file in os.listdir(original_dir):\n",
    "            img_path = os.path.join(original_dir, img_file)\n",
    "            mask_file = img_file  # Asumimos que la máscara tiene el mismo nombre\n",
    "            mask_path = os.path.join(no_bg_dir, mask_file)\n",
    "\n",
    "            if os.path.isfile(img_path) and os.path.isfile(mask_path):\n",
    "                # Generar nuevos nombres para imágenes y máscaras\n",
    "                new_img_name = f\"{image_count:04d}_image.jpg\"\n",
    "                new_mask_name = f\"{image_count:04d}_mask.png\"\n",
    "\n",
    "                # Mover archivos\n",
    "                shutil.move(img_path, os.path.join(images_dir, new_img_name))\n",
    "                shutil.move(mask_path, os.path.join(masks_dir, new_mask_name))\n",
    "\n",
    "                image_count += 1\n",
    "            else:\n",
    "                print(f\"Skipping: Image or mask missing for {img_file} in {subfolder}.\")\n",
    "\n",
    "    print(f\"Reorganized {image_count} images and masks into {images_dir} and {masks_dir}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dataset files are consistent!\n",
      "Dataset is consistent. Proceeding to rename images...\n",
      "Reorganized 150 images and masks into ../data/images and ../data/masks.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Directorios base\n",
    "    base_path = \"../data/public_hand_dataset/\"    \n",
    "    output_images_dir = \"../data/images\"\n",
    "    output_masks_dir = \"../data/masks\"\n",
    "    \n",
    "    # Step 1: Check consistency\n",
    "    inconsistencies = check_dataset_consistency(base_path)\n",
    "    if inconsistencies:\n",
    "        print(\"Inconsistencies found:\")\n",
    "        for issue in inconsistencies:\n",
    "            print(issue)\n",
    "    else:\n",
    "        print(\"Dataset is consistent. Proceeding to rename images...\")\n",
    "\n",
    "        # Step 2: Rename images\n",
    "        move_files(base_path, output_images_dir, output_masks_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
